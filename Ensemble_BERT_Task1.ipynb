{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Ensemble_BERT_Task1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "dde1d669a010471d9aabcc862e66a58f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_40fdca5305ec4b23b6b1364337dfce16",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6a7a4e9e0e994cde9b54f4320cc50051",
              "IPY_MODEL_b18046a6c7e1473a923d89927664f691"
            ]
          }
        },
        "40fdca5305ec4b23b6b1364337dfce16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6a7a4e9e0e994cde9b54f4320cc50051": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_968d809841ce461ea3aec4457ae07498",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_81cbe83aaa9c42b8aac296c197026f23"
          }
        },
        "b18046a6c7e1473a923d89927664f691": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6c0ac2d4dbc34cc6ae6b988ece644c46",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 1.60MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8be37bbc27a84aa3a15442b39d8db688"
          }
        },
        "968d809841ce461ea3aec4457ae07498": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "81cbe83aaa9c42b8aac296c197026f23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6c0ac2d4dbc34cc6ae6b988ece644c46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8be37bbc27a84aa3a15442b39d8db688": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "672beb53dfbd4cf49aacb1e045a5a239": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_bf67f70082c94ce7b5be3c6615ad19a7",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d86e92834ca443a192df0a7f0d98b2c3",
              "IPY_MODEL_2d6053576e334bd0a62b1d12a03d7b49"
            ]
          }
        },
        "bf67f70082c94ce7b5be3c6615ad19a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d86e92834ca443a192df0a7f0d98b2c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b775670aa6e346e5be6a07645a4109cd",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c1efa44d0854442aae1e08047675ee95"
          }
        },
        "2d6053576e334bd0a62b1d12a03d7b49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bc1be185f1914acea221b419f5514188",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28.0/28.0 [00:00&lt;00:00, 135B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d450929f14ac4c3189d83c41729005ea"
          }
        },
        "b775670aa6e346e5be6a07645a4109cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c1efa44d0854442aae1e08047675ee95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bc1be185f1914acea221b419f5514188": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d450929f14ac4c3189d83c41729005ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "82a8ed01db2b48d3a5cca5079a3487c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_fc204245e3994089bb8b0a589e3039d5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_319e3903b1eb47f891c4488d9a97bc27",
              "IPY_MODEL_44c0ab7f6f5e499abfebf373ecaef0c2"
            ]
          }
        },
        "fc204245e3994089bb8b0a589e3039d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "319e3903b1eb47f891c4488d9a97bc27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8775a7ca180b43e4a94d38f86ffedc5c",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a9c388f40fd14130bf38dbdf6545c1a2"
          }
        },
        "44c0ab7f6f5e499abfebf373ecaef0c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e376c00901364d878aba1b25516f9b23",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 466k/466k [00:00&lt;00:00, 4.48MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b57134bd78bd44f6b4900b1ef9ce1540"
          }
        },
        "8775a7ca180b43e4a94d38f86ffedc5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a9c388f40fd14130bf38dbdf6545c1a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e376c00901364d878aba1b25516f9b23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b57134bd78bd44f6b4900b1ef9ce1540": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "76e99f188d2e4764adc63e04065834a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8b36bdd0b2f449eb88aabf8774e0168e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8f99c46bd0b14ab080499a7efcb92b56",
              "IPY_MODEL_b26f4b45dc6145afb733d99f26bcb89b"
            ]
          }
        },
        "8b36bdd0b2f449eb88aabf8774e0168e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8f99c46bd0b14ab080499a7efcb92b56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_29a2e6c8c25a4b8796d61bf7681d5bb2",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_024f2cdc0f6f4be4bc04ecf0f638ebfb"
          }
        },
        "b26f4b45dc6145afb733d99f26bcb89b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_64a1b18a1f2045329af02f22b2becc62",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:00&lt;00:00, 1.01kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f6e7fc274d1e421f8a9b654f30a51143"
          }
        },
        "29a2e6c8c25a4b8796d61bf7681d5bb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "024f2cdc0f6f4be4bc04ecf0f638ebfb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "64a1b18a1f2045329af02f22b2becc62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f6e7fc274d1e421f8a9b654f30a51143": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nk3843/Thesis/blob/main/Ensemble_BERT_Task1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6Rj-7pCHz5D",
        "outputId": "9544f966-803c-4d60-8568-f50854030c9b"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/b2/57495b5309f09fa501866e225c84532d1fd89536ea62406b2181933fb418/transformers-4.5.1-py3-none-any.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 17.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 51.0MB/s \n",
            "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 50.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.10.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Installing collected packages: sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.45 tokenizers-0.10.2 transformers-4.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DllFgq0BA3S-"
      },
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():    \n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jaD-nuuzA4lo",
        "outputId": "3ab65e06-d4f1-4661-ac7b-cd49fb3434e4"
      },
      "source": [
        "import pandas as pd\n",
        "import math\n",
        "from sklearn import preprocessing\n",
        "\n",
        "\n",
        "task = 'task_1'\n",
        "\n",
        "#2019 datasets \n",
        "\n",
        "df_test = pd.read_csv(\"hasoc2019_en_test-2919.tsv\",sep='\\t')\n",
        "df_train = pd.read_csv(\"english_dataset.tsv\",sep=\"\\t\")\n",
        "df_train = df_train.dropna()\n",
        "\n",
        "\n",
        "\n",
        "print(len(df_train))\n",
        "print(df_train.head())\n",
        "\n",
        "total_sentences = list(df_train['text'].values)\n",
        "total_labels = list(df_train[task].values)\n",
        "\n",
        "\n",
        "\n",
        "test_sentences = list(df_test['text'].values)\n",
        "test_labels = list(df_test[task].values)\n",
        "\n",
        "def clean_text(sentences):\n",
        "    for index,line in enumerate(sentences):\n",
        "        if \"\\n\" in line:\n",
        "            sentences[index] = line.replace(\"\\n\",\"\")\n",
        "    return sentences\n",
        "        \n",
        "total_sentences = clean_text(total_sentences)\n",
        "test_sentences = clean_text(test_sentences)\n",
        "\n",
        "def clean_labels(labels):\n",
        "    new_list= []\n",
        "    for value in labels:\n",
        "        new_list.append(value.strip())\n",
        "    return new_list\n",
        "\n",
        "total_labels = clean_labels(total_labels)\n",
        "test_labels = clean_labels(test_labels)\n",
        "\n",
        "le = preprocessing.LabelEncoder()\n",
        "le.fit(total_labels)\n",
        "encoded_labels = le.transform(total_labels)\n",
        "encoded_test_labels = le.transform(test_labels)\n",
        "print(set(encoded_labels))\n",
        "\n",
        "print(len(total_sentences),len(encoded_labels),len(test_sentences),len(encoded_test_labels))\n",
        "\n",
        "print(df_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5852\n",
            "      text_id                                               text  ... task_2 task_3\n",
            "0  hasoc_en_1  #DhoniKeepsTheGlove | WATCH: Sports Minister K...  ...   NONE   NONE\n",
            "1  hasoc_en_2  @politico No. We should remember very clearly ...  ...   HATE    TIN\n",
            "2  hasoc_en_3  @cricketworldcup Guess who would be the winner...  ...   NONE   NONE\n",
            "3  hasoc_en_4  Corbyn is too politically intellectual for #Bo...  ...   NONE   NONE\n",
            "4  hasoc_en_5  All the best to #TeamIndia for another swimmin...  ...   NONE   NONE\n",
            "\n",
            "[5 rows x 5 columns]\n",
            "{0, 1}\n",
            "5852 5852 1153 1153\n",
            "             text_id  ... task_3\n",
            "0       hasoc_en_902  ...   NONE\n",
            "1       hasoc_en_416  ...   NONE\n",
            "2       hasoc_en_207  ...   NONE\n",
            "3       hasoc_en_595  ...   NONE\n",
            "4       hasoc_en_568  ...    UNT\n",
            "...              ...  ...    ...\n",
            "1148  hasoc_en1_3958  ...   NONE\n",
            "1149  hasoc_en1_4648  ...   NONE\n",
            "1150  hasoc_en1_4832  ...   NONE\n",
            "1151  hasoc_en1_3721  ...   NONE\n",
            "1152   hasoc_en1_991  ...   NONE\n",
            "\n",
            "[1153 rows x 5 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WrNNM4Eya0iK",
        "outputId": "2d7e52ab-94a9-4e6e-e144-ae458361fe3f"
      },
      "source": [
        "SEED = 42\n",
        "torch.manual_seed(SEED)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f9ccf153b10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185,
          "referenced_widgets": [
            "dde1d669a010471d9aabcc862e66a58f",
            "40fdca5305ec4b23b6b1364337dfce16",
            "6a7a4e9e0e994cde9b54f4320cc50051",
            "b18046a6c7e1473a923d89927664f691",
            "968d809841ce461ea3aec4457ae07498",
            "81cbe83aaa9c42b8aac296c197026f23",
            "6c0ac2d4dbc34cc6ae6b988ece644c46",
            "8be37bbc27a84aa3a15442b39d8db688",
            "672beb53dfbd4cf49aacb1e045a5a239",
            "bf67f70082c94ce7b5be3c6615ad19a7",
            "d86e92834ca443a192df0a7f0d98b2c3",
            "2d6053576e334bd0a62b1d12a03d7b49",
            "b775670aa6e346e5be6a07645a4109cd",
            "c1efa44d0854442aae1e08047675ee95",
            "bc1be185f1914acea221b419f5514188",
            "d450929f14ac4c3189d83c41729005ea",
            "82a8ed01db2b48d3a5cca5079a3487c1",
            "fc204245e3994089bb8b0a589e3039d5",
            "319e3903b1eb47f891c4488d9a97bc27",
            "44c0ab7f6f5e499abfebf373ecaef0c2",
            "8775a7ca180b43e4a94d38f86ffedc5c",
            "a9c388f40fd14130bf38dbdf6545c1a2",
            "e376c00901364d878aba1b25516f9b23",
            "b57134bd78bd44f6b4900b1ef9ce1540"
          ]
        },
        "id": "wYZGhJ_4C-Dq",
        "outputId": "a4328f5a-d900-4c7c-c633-1b9f54560940"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "max_length = 0\n",
        "for sentence in total_sentences:\n",
        "    #print(sentence)\n",
        "    length = len(tokenizer.tokenize(sentence))\n",
        "    if length > max_length:\n",
        "        max_length  = length\n",
        "print(\"max token length is: \",max_length)\n",
        "# max token length obtained is 50\n",
        "\n",
        "# bert tokens are limited to 514 bytes."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dde1d669a010471d9aabcc862e66a58f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "672beb53dfbd4cf49aacb1e045a5a239",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "82a8ed01db2b48d3a5cca5079a3487c1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "max token length is:  399\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VwTBUNhEHzZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e54f1888-0adb-4919-a7be-141683fbeb32"
      },
      "source": [
        "def encoder_generator(sentences,labels):\n",
        "    \n",
        "    sent_index = []\n",
        "    input_ids = []\n",
        "    attention_masks =[]\n",
        "\n",
        "    for index,sent in enumerate(sentences):\n",
        "        \n",
        "        sent_index.append(index)\n",
        "        \n",
        "        encoded_dict = tokenizer.encode_plus(sent,\n",
        "                                             add_special_tokens=True,\n",
        "                                             max_length=128,\n",
        "                                             pad_to_max_length=True,\n",
        "                                             truncation = True,\n",
        "                                             return_attention_mask=True,\n",
        "                                             return_tensors='pt')\n",
        "        input_ids.append(encoded_dict['input_ids'])\n",
        "\n",
        "        attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "    input_ids = torch.cat(input_ids,dim=0)\n",
        "    attention_masks = torch.cat(attention_masks,dim=0)\n",
        "    labels = torch.tensor(labels)\n",
        "    sent_index = torch.tensor(sent_index)\n",
        "\n",
        "    return sent_index,input_ids,attention_masks,labels\n",
        "\n",
        "sent_index,input_ids,attention_masks,encoded_label_tensors = encoder_generator(total_sentences,encoded_labels)\n",
        "test_sent_index,test_input_ids,test_attention_masks,encoded_test_label_tensors = encoder_generator(test_sentences,encoded_test_labels)\n",
        "print('Original: ', total_sentences[0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Original:  #DhoniKeepsTheGlove | WATCH: Sports Minister Kiren Rijiju issues statement backing MS Dhoni over 'Balidaan Badge', tells BCCI to take up the matter with ICC and keep government in the know as nation's pride is involved    https://t.co/zuo5335Rjr\n",
            "Token IDs: tensor([  101,  1001, 28144, 10698, 20553,  4523, 10760, 23296, 21818,  1064,\n",
            "         3422,  1024,  2998,  2704, 11382,  7389, 15544,  4478,  9103,  3314,\n",
            "         4861,  5150,  5796, 28144, 10698,  2058,  1005, 20222,  2850,  2319,\n",
            "        10780,  1005,  1010,  4136,  4647,  6895,  2000,  2202,  2039,  1996,\n",
            "         3043,  2007, 16461,  1998,  2562,  2231,  1999,  1996,  2113,  2004,\n",
            "         3842,  1005,  1055,  6620,  2003,  2920, 16770,  1024,  1013,  1013,\n",
            "         1056,  1012,  2522,  1013, 16950,  2080, 22275, 19481,  2099,  3501,\n",
            "         2099,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIaQBoXwEhPF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbcef497-7b75-404f-f43c-5084dfa4d3a4"
      },
      "source": [
        "from torch.utils.data import TensorDataset,random_split\n",
        "\n",
        "dataset = TensorDataset(input_ids,attention_masks,encoded_label_tensors)\n",
        "test_dataset = TensorDataset(test_sent_index,test_input_ids,test_attention_masks,encoded_test_label_tensors)\n",
        "\n",
        "train_size = int(0.75*len(dataset))\n",
        "\n",
        "val_size = len(dataset)-train_size\n",
        "\n",
        "train_dataset,val_dataset = random_split(dataset,[train_size,val_size])\n",
        "\n",
        "print('train data samples is {}'.format(len(train_dataset)))\n",
        "print(\"valid data samples is {}\".format(len(val_dataset)))\n",
        "print(\"test data samples is {}\".format(len(test_dataset)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train data samples is 4389\n",
            "valid data samples is 1463\n",
            "test data samples is 1153\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8FTVcl6Eowm"
      },
      "source": [
        "from torch.utils.data import DataLoader,RandomSampler,SequentialSampler\n",
        "\n",
        "bs=8\n",
        "\n",
        "train_data_loader = DataLoader(train_dataset,\n",
        "                              sampler=RandomSampler(train_dataset),\n",
        "                              batch_size=bs)\n",
        "valid_data_loader = DataLoader(val_dataset,\n",
        "                              sampler=SequentialSampler(val_dataset),\n",
        "                              batch_size=bs)\n",
        "test_data_loader = DataLoader(test_dataset,\n",
        "                            sampler=SequentialSampler(test_dataset),\n",
        "                            batch_size=bs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6U-Clv0XDSPi"
      },
      "source": [
        "device = \"cuda:0\"\n",
        "torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NlmHevcbJUUi"
      },
      "source": [
        "from transformers import BertPreTrainedModel,BertForSequenceClassification\n",
        "from transformers.modeling_outputs import SequenceClassifierOutput"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLE7DOqQgNe4"
      },
      "source": [
        "import torch.nn as nn\n",
        "from torch.nn import CrossEntropyLoss\n",
        "class BertEnsemble(BertPreTrainedModel):\n",
        "  def __init__(self, config,num_labels):\n",
        "      super().__init__(config)\n",
        "      self.num_labels = num_labels\n",
        "      torch.manual_seed(1)\n",
        "      self.model_1 = BertForSequenceClassification(config\n",
        "                                                      )\n",
        "      torch.manual_seed(2)\n",
        "      self.model_2 = BertForSequenceClassification(config\n",
        "                                                      )\n",
        "      self.classifier = nn.Linear(2* self.num_labels,self.num_labels)\n",
        "      self.init_weights()\n",
        "\n",
        "  def forward(self,\n",
        "              input_ids=None, \n",
        "              attention_mask=None, \n",
        "              token_type_ids=None, \n",
        "              position_ids=None, \n",
        "              head_mask=None, \n",
        "              inputs_embeds=None, \n",
        "              labels=None, \n",
        "              output_attentions=None, \n",
        "              output_hidden_states=None, \n",
        "              return_dict=None):\n",
        "      outputs = []\n",
        "      outputs.append(self.model_1(\n",
        "            input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "            position_ids=position_ids,\n",
        "            head_mask=head_mask,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "            output_attentions=output_attentions,\n",
        "            output_hidden_states=output_hidden_states,\n",
        "            return_dict=return_dict,\n",
        "        ))\n",
        "      \n",
        "      outputs.append(self.model_2(\n",
        "            input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "            position_ids=position_ids,\n",
        "            head_mask=head_mask,\n",
        "            inputs_embeds=inputs_embeds,\n",
        "            output_attentions=output_attentions,\n",
        "            output_hidden_states=output_hidden_states,\n",
        "            return_dict=return_dict,\n",
        "      ))\n",
        "      \n",
        "      last_hidden_states = torch.cat([output.logits for output in outputs], dim=1)\n",
        "\n",
        "      \n",
        "      logits = self.classifier(last_hidden_states)\n",
        "\n",
        "      loss = None    \n",
        "      loss_fct = CrossEntropyLoss()\n",
        "      loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
        "\n",
        "      return SequenceClassifierOutput(\n",
        "          loss=loss,\n",
        "          logits=logits,\n",
        "          hidden_states=None,\n",
        "          attentions=None,\n",
        "      )\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1tEI8JEh3D8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "76e99f188d2e4764adc63e04065834a5",
            "8b36bdd0b2f449eb88aabf8774e0168e",
            "8f99c46bd0b14ab080499a7efcb92b56",
            "b26f4b45dc6145afb733d99f26bcb89b",
            "29a2e6c8c25a4b8796d61bf7681d5bb2",
            "024f2cdc0f6f4be4bc04ecf0f638ebfb",
            "64a1b18a1f2045329af02f22b2becc62",
            "f6e7fc274d1e421f8a9b654f30a51143"
          ]
        },
        "outputId": "f5e516ba-88ec-4ea0-be71-f7ed5ed678a2"
      },
      "source": [
        "from transformers import AutoConfig \n",
        "config = AutoConfig.from_pretrained('bert-base-uncased',\n",
        "                                    output_attentions=False,\n",
        "                                    output_hidden_states=False,)\n",
        "model = BertEnsemble(config,num_labels=len(le.classes_))\n",
        "model.to(device)\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "76e99f188d2e4764adc63e04065834a5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertEnsemble(\n",
              "  (model_1): BertForSequenceClassification(\n",
              "    (bert): BertModel(\n",
              "      (embeddings): BertEmbeddings(\n",
              "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "        (position_embeddings): Embedding(512, 768)\n",
              "        (token_type_embeddings): Embedding(2, 768)\n",
              "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (encoder): BertEncoder(\n",
              "        (layer): ModuleList(\n",
              "          (0): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (1): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (2): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (3): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (4): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (5): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (6): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (7): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (8): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (9): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (10): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (11): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (pooler): BertPooler(\n",
              "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (activation): Tanh()\n",
              "      )\n",
              "    )\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              "  )\n",
              "  (model_2): BertForSequenceClassification(\n",
              "    (bert): BertModel(\n",
              "      (embeddings): BertEmbeddings(\n",
              "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "        (position_embeddings): Embedding(512, 768)\n",
              "        (token_type_embeddings): Embedding(2, 768)\n",
              "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (encoder): BertEncoder(\n",
              "        (layer): ModuleList(\n",
              "          (0): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (1): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (2): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (3): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (4): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (5): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (6): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (7): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (8): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (9): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (10): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (11): BertLayer(\n",
              "            (attention): BertAttention(\n",
              "              (self): BertSelfAttention(\n",
              "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): BertSelfOutput(\n",
              "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): BertIntermediate(\n",
              "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            )\n",
              "            (output): BertOutput(\n",
              "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (pooler): BertPooler(\n",
              "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (activation): Tanh()\n",
              "      )\n",
              "    )\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              "  )\n",
              "  (classifier): Linear(in_features=4, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQrCpsyeM8wo"
      },
      "source": [
        "from transformers import AdamW\n",
        "optimizer = AdamW(model.parameters(),lr=2e-5,eps=1e-8)\n",
        "\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "epochs=10\n",
        "total_steps = len(train_data_loader) * epochs\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                           num_warmup_steps=0,\n",
        "                                           num_training_steps=total_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nREL2AQFNZt"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def predictions_labels(preds,labels):\n",
        "    #print(preds.device,labels.device)\n",
        "    pred = torch.argmax(preds,axis=1).flatten()\n",
        "    label = labels.flatten()\n",
        "    return pred,label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HPQl9hWFSd3"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import time\n",
        "from sklearn.metrics import classification_report,accuracy_score,f1_score\n",
        "\n",
        "total_t0 = time.time()\n",
        "\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDFflMIcFVs9"
      },
      "source": [
        "def categorical_accuracy(preds, y):\n",
        "    \"\"\"\n",
        "    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n",
        "    \"\"\"\n",
        "    max_preds = preds.argmax(dim = 1, keepdim = True) # get the index of the max probability\n",
        "    correct = max_preds.squeeze(1).eq(y)\n",
        "    #print(correct.device)\n",
        "    return correct.sum() / torch.FloatTensor([y.shape[0]]).to(device)\n",
        "\n",
        "def predictions_labels(preds,labels):\n",
        "    #print(preds.device,labels.device)\n",
        "    pred = torch.argmax(preds,axis=1).flatten()\n",
        "    label = labels.flatten()\n",
        "    return pred,label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvi36_J7FZy9"
      },
      "source": [
        "def train():\n",
        "  total_train_loss = 0\n",
        "  total_train_acc = 0\n",
        "    \n",
        "  model.train() # set model in train mode for batchnorm and dropout layers in bert model\n",
        "    \n",
        "  for step,batch in enumerate(train_data_loader):\n",
        "    #print(\"**************************************************************************\")\n",
        "    #print(\"Step : \",step,\"  batch\",len(batch))\n",
        "    #print(\"**************************************************************************\")\n",
        "    b_input_ids = batch[0].to(device)\n",
        "    b_input_mask = batch[1].to(device)\n",
        "    b_labels = batch[2].to(device)\n",
        "    model.zero_grad()\n",
        "    #loss,logits = model(b_input_ids,attention_mask=b_input_mask,labels=b_labels.long())\n",
        "    outputs = model(b_input_ids,attention_mask=b_input_mask,labels=b_labels.long())\n",
        "    #print(outputs)\n",
        "    loss = outputs.loss\n",
        "    logits = outputs.logits\n",
        "    #total_train_loss+=loss.detach().numpy()\n",
        "    total_train_loss+=loss.detach()\n",
        "    total_train_acc+=categorical_accuracy(logits,b_labels).item()\n",
        "            \n",
        "    loss.backward()\n",
        "            \n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(),1.0)\n",
        "            \n",
        "    optimizer.step()\n",
        "            \n",
        "    scheduler.step() #go ahead and update the learning rate\n",
        "    #print(total_train_loss,total_train_acc)\n",
        "            \n",
        "  avg_train_loss = total_train_loss/len(train_data_loader)\n",
        "  avg_train_acc = total_train_acc/len(train_data_loader)\n",
        "    \n",
        "  return avg_train_loss,avg_train_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FS3kPLQMFgOG"
      },
      "source": [
        "def evaluate():\n",
        "    model.eval()\n",
        "        \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    number_of_eval_steps= 0\n",
        "    \n",
        "    all_true_labels = []\n",
        "    all_pred_labels = []\n",
        "\n",
        "    for batch in valid_data_loader:\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "\n",
        "        #loss, logits = model(b_input_ids,attention_mask= b_input_mask,labels = b_labels.long())\n",
        "          outputs = model(b_input_ids,attention_mask=b_input_mask,labels=b_labels.long())\n",
        "        loss = outputs.loss\n",
        "        logits = outputs.logits\n",
        "\n",
        "        #total_eval_loss+=loss.detach().numpy()\n",
        "\n",
        "        #logits = logits.detach().cpu().numpy()\n",
        "        #label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        total_eval_loss+=loss.detach()        \n",
        "        logits = logits.detach()\n",
        "        label_ids = b_labels.to(device)\n",
        "\n",
        "        pred,true = predictions_labels(logits,label_ids)\n",
        "        \n",
        "        all_pred_labels.extend(pred.detach().cpu().numpy())\n",
        "        all_true_labels.extend(true.detach().cpu().numpy())\n",
        "    \n",
        "    #print(np.shape(np.array(all_pred_labels).reshape(-1,1)),np.shape(np.array(all_true_labels).reshape(-1,1)))\n",
        "\n",
        "    print(classification_report(all_pred_labels,all_true_labels))\n",
        "    avg_val_accuracy = accuracy_score(all_pred_labels,all_true_labels)\n",
        "    macro_f1_score = f1_score(all_pred_labels,all_true_labels,average='macro')\n",
        "    \n",
        "    avg_val_loss = total_eval_loss/len(valid_data_loader)\n",
        "\n",
        "    print(\"accuracy = {0:.2f}\".format(avg_val_accuracy))\n",
        "    \n",
        "    return avg_val_loss,avg_val_accuracy,macro_f1_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLQ5ATlIFoMz"
      },
      "source": [
        "import time\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmNn6N7wFtj1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfc9775b-f527-40c9-af87-a9498722a161"
      },
      "source": [
        "epochs = 50\n",
        "train_loss = 0\n",
        "train_acc = 0\n",
        "valid_loss = 0\n",
        "valid_acc = 0\n",
        "macro_f1  = 0\n",
        "best_macro_f1 = float('0')\n",
        "for epoch in range(epochs):\n",
        "  start_time = time.time()\n",
        "  train_loss,train_acc = train()\n",
        "  valid_loss,valid_acc,macro_f1 = evaluate()\n",
        "    \n",
        "  end_time = time.time()\n",
        "        \n",
        "  epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "        \n",
        "  if macro_f1 > best_macro_f1:\n",
        "    best_macro_f1 = macro_f1\n",
        "    torch.save(model,'model_english_task_a.pt')\n",
        "  \n",
        "  print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "  print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "  print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
        "  #print(f'\\t macro_f1: {macro_f1:.3f} |  c: {valid_acc*100:.2f}%')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         0\n",
            "           1       1.00      0.61      0.76      1463\n",
            "\n",
            "    accuracy                           0.61      1463\n",
            "   macro avg       0.50      0.31      0.38      1463\n",
            "weighted avg       1.00      0.61      0.76      1463\n",
            "\n",
            "accuracy = 0.61\n",
            "Epoch: 01 | Epoch Time: 4m 17s\n",
            "\tTrain Loss: 0.668 | Train Acc: 61.47%\n",
            "\t Val. Loss: 0.670 |  Val. Acc: 61.04%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         0\n",
            "           1       1.00      0.61      0.76      1463\n",
            "\n",
            "    accuracy                           0.61      1463\n",
            "   macro avg       0.50      0.31      0.38      1463\n",
            "weighted avg       1.00      0.61      0.76      1463\n",
            "\n",
            "accuracy = 0.61\n",
            "Epoch: 02 | Epoch Time: 4m 21s\n",
            "\tTrain Loss: 0.667 | Train Acc: 61.29%\n",
            "\t Val. Loss: 0.671 |  Val. Acc: 61.04%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         0\n",
            "           1       1.00      0.61      0.76      1463\n",
            "\n",
            "    accuracy                           0.61      1463\n",
            "   macro avg       0.50      0.31      0.38      1463\n",
            "weighted avg       1.00      0.61      0.76      1463\n",
            "\n",
            "accuracy = 0.61\n",
            "Epoch: 03 | Epoch Time: 4m 21s\n",
            "\tTrain Loss: 0.667 | Train Acc: 61.47%\n",
            "\t Val. Loss: 0.661 |  Val. Acc: 61.04%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         0\n",
            "           1       1.00      0.61      0.76      1463\n",
            "\n",
            "    accuracy                           0.61      1463\n",
            "   macro avg       0.50      0.31      0.38      1463\n",
            "weighted avg       1.00      0.61      0.76      1463\n",
            "\n",
            "accuracy = 0.61\n",
            "Epoch: 04 | Epoch Time: 4m 21s\n",
            "\tTrain Loss: 0.659 | Train Acc: 61.41%\n",
            "\t Val. Loss: 0.652 |  Val. Acc: 61.04%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         0\n",
            "           1       1.00      0.61      0.76      1463\n",
            "\n",
            "    accuracy                           0.61      1463\n",
            "   macro avg       0.50      0.31      0.38      1463\n",
            "weighted avg       1.00      0.61      0.76      1463\n",
            "\n",
            "accuracy = 0.61\n",
            "Epoch: 05 | Epoch Time: 4m 22s\n",
            "\tTrain Loss: 0.639 | Train Acc: 61.48%\n",
            "\t Val. Loss: 0.639 |  Val. Acc: 61.04%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.42      0.58      0.49       415\n",
            "           1       0.80      0.69      0.74      1048\n",
            "\n",
            "    accuracy                           0.65      1463\n",
            "   macro avg       0.61      0.63      0.61      1463\n",
            "weighted avg       0.70      0.65      0.67      1463\n",
            "\n",
            "accuracy = 0.65\n",
            "Epoch: 06 | Epoch Time: 4m 22s\n",
            "\tTrain Loss: 0.615 | Train Acc: 66.56%\n",
            "\t Val. Loss: 0.636 |  Val. Acc: 65.48%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.63      0.54      0.58       656\n",
            "           1       0.67      0.74      0.70       807\n",
            "\n",
            "    accuracy                           0.65      1463\n",
            "   macro avg       0.65      0.64      0.64      1463\n",
            "weighted avg       0.65      0.65      0.65      1463\n",
            "\n",
            "accuracy = 0.65\n",
            "Epoch: 07 | Epoch Time: 4m 21s\n",
            "\tTrain Loss: 0.590 | Train Acc: 72.59%\n",
            "\t Val. Loss: 0.633 |  Val. Acc: 65.00%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.59      0.55      0.57       606\n",
            "           1       0.70      0.72      0.71       857\n",
            "\n",
            "    accuracy                           0.65      1463\n",
            "   macro avg       0.64      0.64      0.64      1463\n",
            "weighted avg       0.65      0.65      0.65      1463\n",
            "\n",
            "accuracy = 0.65\n",
            "Epoch: 08 | Epoch Time: 4m 21s\n",
            "\tTrain Loss: 0.570 | Train Acc: 74.55%\n",
            "\t Val. Loss: 0.631 |  Val. Acc: 65.28%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.28      0.62      0.39       261\n",
            "           1       0.89      0.66      0.76      1202\n",
            "\n",
            "    accuracy                           0.65      1463\n",
            "   macro avg       0.59      0.64      0.57      1463\n",
            "weighted avg       0.78      0.65      0.69      1463\n",
            "\n",
            "accuracy = 0.65\n",
            "Epoch: 09 | Epoch Time: 4m 21s\n",
            "\tTrain Loss: 0.543 | Train Acc: 77.10%\n",
            "\t Val. Loss: 0.652 |  Val. Acc: 65.21%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.59      0.52       458\n",
            "           1       0.79      0.70      0.74      1005\n",
            "\n",
            "    accuracy                           0.66      1463\n",
            "   macro avg       0.63      0.64      0.63      1463\n",
            "weighted avg       0.69      0.66      0.67      1463\n",
            "\n",
            "accuracy = 0.66\n",
            "Epoch: 10 | Epoch Time: 4m 21s\n",
            "\tTrain Loss: 0.532 | Train Acc: 78.11%\n",
            "\t Val. Loss: 0.634 |  Val. Acc: 66.37%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.59      0.52       458\n",
            "           1       0.79      0.70      0.74      1005\n",
            "\n",
            "    accuracy                           0.66      1463\n",
            "   macro avg       0.63      0.64      0.63      1463\n",
            "weighted avg       0.69      0.66      0.67      1463\n",
            "\n",
            "accuracy = 0.66\n",
            "Epoch: 11 | Epoch Time: 4m 21s\n",
            "\tTrain Loss: 0.527 | Train Acc: 78.66%\n",
            "\t Val. Loss: 0.634 |  Val. Acc: 66.37%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.59      0.52       458\n",
            "           1       0.79      0.70      0.74      1005\n",
            "\n",
            "    accuracy                           0.66      1463\n",
            "   macro avg       0.63      0.64      0.63      1463\n",
            "weighted avg       0.69      0.66      0.67      1463\n",
            "\n",
            "accuracy = 0.66\n",
            "Epoch: 12 | Epoch Time: 4m 22s\n",
            "\tTrain Loss: 0.526 | Train Acc: 78.72%\n",
            "\t Val. Loss: 0.634 |  Val. Acc: 66.37%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.59      0.52       458\n",
            "           1       0.79      0.70      0.74      1005\n",
            "\n",
            "    accuracy                           0.66      1463\n",
            "   macro avg       0.63      0.64      0.63      1463\n",
            "weighted avg       0.69      0.66      0.67      1463\n",
            "\n",
            "accuracy = 0.66\n",
            "Epoch: 13 | Epoch Time: 4m 21s\n",
            "\tTrain Loss: 0.527 | Train Acc: 78.56%\n",
            "\t Val. Loss: 0.634 |  Val. Acc: 66.37%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.59      0.52       458\n",
            "           1       0.79      0.70      0.74      1005\n",
            "\n",
            "    accuracy                           0.66      1463\n",
            "   macro avg       0.63      0.64      0.63      1463\n",
            "weighted avg       0.69      0.66      0.67      1463\n",
            "\n",
            "accuracy = 0.66\n",
            "Epoch: 14 | Epoch Time: 4m 21s\n",
            "\tTrain Loss: 0.527 | Train Acc: 78.49%\n",
            "\t Val. Loss: 0.634 |  Val. Acc: 66.37%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.59      0.52       458\n",
            "           1       0.79      0.70      0.74      1005\n",
            "\n",
            "    accuracy                           0.66      1463\n",
            "   macro avg       0.63      0.64      0.63      1463\n",
            "weighted avg       0.69      0.66      0.67      1463\n",
            "\n",
            "accuracy = 0.66\n",
            "Epoch: 15 | Epoch Time: 4m 21s\n",
            "\tTrain Loss: 0.528 | Train Acc: 78.36%\n",
            "\t Val. Loss: 0.634 |  Val. Acc: 66.37%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.47      0.59      0.52       458\n",
            "           1       0.79      0.70      0.74      1005\n",
            "\n",
            "    accuracy                           0.66      1463\n",
            "   macro avg       0.63      0.64      0.63      1463\n",
            "weighted avg       0.69      0.66      0.67      1463\n",
            "\n",
            "accuracy = 0.66\n",
            "Epoch: 16 | Epoch Time: 4m 22s\n",
            "\tTrain Loss: 0.526 | Train Acc: 78.73%\n",
            "\t Val. Loss: 0.634 |  Val. Acc: 66.37%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZDTn7vd0K0M"
      },
      "source": [
        "del model\n",
        "import gc\n",
        "gc.collect()\n",
        "  \n",
        "model = torch.load('model_english_task_a.pt')\n",
        "model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhIT-nGy0M3a"
      },
      "source": [
        "def evaluate_test():\n",
        "    model.eval()\n",
        "        \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    number_of_eval_steps= 0\n",
        "    \n",
        "    all_true_labels = []\n",
        "    all_pred_labels = []\n",
        "    \n",
        "    all_sentence_id=[]\n",
        "\n",
        "    for batch in test_data_loader:\n",
        "        b_sentence_id = batch[0].to(device)\n",
        "        b_input_ids = batch[1].to(device)\n",
        "        b_input_mask = batch[2].to(device)\n",
        "        b_labels = batch[3].to(device)\n",
        "\n",
        "        sent_ids = b_sentence_id.to('cpu').numpy()\n",
        "        all_sentence_id.extend(sent_ids)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "\n",
        "            outputs = model(b_input_ids,\n",
        "                                attention_mask= b_input_mask,\n",
        "                                labels = b_labels.long())\n",
        "        \n",
        "        loss = outputs.loss\n",
        "        logits = outputs.logits\n",
        "\n",
        "        total_eval_loss+=loss.item()\n",
        "\n",
        "        logits = logits.detach().cpu()\n",
        "\n",
        "        label_ids = b_labels.to('cpu')\n",
        "        \n",
        "\n",
        "        pred,true = predictions_labels(logits,label_ids)\n",
        "        \n",
        "        all_pred_labels.extend(pred)\n",
        "        \n",
        "        all_true_labels.extend(true)\n",
        "\n",
        "    print(classification_report(all_pred_labels,all_true_labels))\n",
        "    avg_val_accuracy = accuracy_score(all_pred_labels,all_true_labels)\n",
        "    \n",
        "    avg_val_loss = total_eval_loss/len(valid_data_loader)\n",
        "\n",
        "    print(\"accuracy = {0:.2f}\".format(avg_val_accuracy))\n",
        "    \n",
        "    return avg_val_loss,avg_val_accuracy,all_sentence_id,all_pred_labels\n",
        "\n",
        "valid_loss,valid_acc,all_sentence_id,all_pred_labels = evaluate_test()\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}